{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "# This is a heading\n",
    "\n",
    "This is some **bold** text, and this is some *italic* text.\n",
    "\n",
    "Here's a list:\n",
    "\n",
    "* Item 1\n",
    "* Item 2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "OAI_KEY=\"INSERT YOUR KEY HERE\"\n",
    "client = OpenAI(api_key=OAI_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import time  # for measuring time duration of API calls\n",
    "from openai import OpenAI\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "from IPython.display import Markdown, JSON, display, Math\n",
    "\n",
    "display(Markdown(completion.choices[0].message.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Completions using Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize OAI client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", OAI_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example of an OpenAI ChatCompletion request\n",
    "# https://platform.openai.com/docs/guides/text-generation/chat-completions-api\n",
    "\n",
    "# record the time before the request is sent\n",
    "start_time = time.time()\n",
    "\n",
    "# send a ChatCompletion request to count to 100\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'Count to 100, with a comma between each number and no newlines. E.g., 1, 2, 3, ...'}\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "# calculate the time it took to receive the response\n",
    "response_time = time.time() - start_time\n",
    "\n",
    "# print the time delay and text received\n",
    "print(f\"Full response received {response_time:.2f} seconds after request\")\n",
    "print(f\"Full response received:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reply = response.choices[0].message\n",
    "display(Markdown(f\"Extracted reply: \\n{reply}\"))\n",
    "\n",
    "reply_content = response.choices[0].message.content\n",
    "display(Markdown(f\"Extracted content: \\n{reply_content}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example of an OpenAI ChatCompletion request with stream=True\n",
    "# https://platform.openai.com/docs/api-reference/streaming#chat/create-stream\n",
    "\n",
    "# a ChatCompletion request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"What's 1+1? Answer in one word.\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# This prints the response as it streams back from the API call\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get token usage data for streamed chat completion responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example of an OpenAI ChatCompletion request with stream=True and stream_options={\"include_usage\": True}\n",
    "\n",
    "# a ChatCompletion request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"What's 1+1? Answer in one word.\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(f\"choices: {chunk.choices}\\nusage: {chunk.usage}\")\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", OAI_KEY))\n",
    "\n",
    "MODEL = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_tutor_prompt = '''\n",
    "    You are a helpful math tutor. You will be provided with a math problem,\n",
    "    and your goal will be to output a step by step solution, along with a final answer.\n",
    "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
    "'''\n",
    "\n",
    "def get_math_solution(question):\n",
    "    response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": dedent(math_tutor_prompt)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": question\n",
    "        }\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"math_reasoning\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"steps\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"explanation\": {\"type\": \"string\"},\n",
    "                                \"output\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"explanation\", \"output\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    },\n",
    "                    \"final_answer\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"steps\", \"final_answer\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing with an example question\n",
    "question = \"how can I solve 8x + 7 = -23\"\n",
    "\n",
    "result = get_math_solution(question)\n",
    "display(Markdown(pprint(json.loads(result.content), depth=3, indent=4, width=160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_math_response(response):\n",
    "    result = json.loads(response)\n",
    "    steps = result['steps']\n",
    "    final_answer = result['final_answer']\n",
    "    for i in range(len(steps)):\n",
    "        print(f\"Step {i+1}: {steps[i]['explanation']}\\n\")\n",
    "        display(Math(steps[i]['output']))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    print(\"Final answer:\\n\\n\")\n",
    "    display(Math(final_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_math_response(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `pydantic` to define a BaseModel and `parsed` helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    class Step(BaseModel):\n",
    "        explanation: str\n",
    "        output: str\n",
    "\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "def get_math_solution(question: str):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": dedent(math_tutor_prompt)},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "        response_format=MathReasoning,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = get_math_solution(question).parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uses model defined above\n",
    "for step in result.steps:\n",
    "    display(Markdown(step.explanation))\n",
    "    display(Markdown(step.output))\n",
    "\n",
    "display(Markdown(f\"Final Answer: {result.final_answer}\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
